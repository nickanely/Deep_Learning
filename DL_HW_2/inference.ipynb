{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=2,\n",
    "                           batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bridge_h = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.bridge_c = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            outputs, (hidden, cell) = self.lstm(packed)\n",
    "            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        else:\n",
    "            outputs, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        hidden_fwd = hidden[-2]\n",
    "        hidden_bwd = hidden[-1]\n",
    "        hidden_combined = torch.cat([hidden_fwd, hidden_bwd], dim=1)\n",
    "        cell_fwd = cell[-2]\n",
    "        cell_bwd = cell[-1]\n",
    "        cell_combined = torch.cat([cell_fwd, cell_bwd], dim=1)\n",
    "\n",
    "        hidden_dec = torch.tanh(self.bridge_h(hidden_combined)).unsqueeze(0)\n",
    "        cell_dec = torch.tanh(self.bridge_c(cell_combined)).unsqueeze(0)\n",
    "        return outputs, (hidden_dec, cell_dec)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, dropout=0.3, encoder_embedding=None):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        if encoder_embedding is not None:\n",
    "            self.embedding = encoder_embedding\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output.squeeze(1))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2SeqSpeller(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, embed_dim, hidden_dim, dropout)\n",
    "        self.decoder = Decoder(vocab_size, embed_dim, hidden_dim, dropout,\n",
    "                               encoder_embedding=self.encoder.embedding)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def forward(self, src, tgt, src_lens, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        max_len = tgt.size(1)\n",
    "        outputs = torch.zeros(batch_size, max_len, self.vocab_size).to(src.device)\n",
    "        _, (hidden, cell) = self.encoder(src, src_lens)\n",
    "        input_token = tgt[:, 0:1]\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            input_token = output.argmax(1, keepdim=True)\n",
    "        return outputs"
   ],
   "id": "854caed15662f3ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.PAD = '<pad>'\n",
    "        self.SOS = '<sos>'\n",
    "        self.EOS = '<eos>'\n",
    "        self.special_tokens = [self.PAD, self.SOS, self.EOS]\n",
    "        self.chars = list('აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ')\n",
    "        self.token_to_idx = {}\n",
    "        self.idx_to_token = {}\n",
    "        all_tokens = self.special_tokens + self.chars\n",
    "        for idx, token in enumerate(all_tokens):\n",
    "            self.token_to_idx[token] = idx\n",
    "            self.idx_to_token[idx] = token\n",
    "        self.pad_idx = self.token_to_idx[self.PAD]\n",
    "        self.sos_idx = self.token_to_idx[self.SOS]\n",
    "        self.eos_idx = self.token_to_idx[self.EOS]\n",
    "        self.vocab_size = len(all_tokens)\n",
    "\n",
    "    def encode(self, word, add_sos=False, add_eos=False):\n",
    "        indices = []\n",
    "        if add_sos:\n",
    "            indices.append(self.sos_idx)\n",
    "        for char in word:\n",
    "            if char in self.token_to_idx:\n",
    "                indices.append(self.token_to_idx[char])\n",
    "        if add_eos:\n",
    "            indices.append(self.eos_idx)\n",
    "        return indices\n",
    "\n",
    "    def decode(self, indices):\n",
    "        chars = []\n",
    "        for idx in indices:\n",
    "            if idx == self.eos_idx:\n",
    "                break\n",
    "            if idx not in [self.pad_idx, self.sos_idx]:\n",
    "                chars.append(self.idx_to_token.get(idx, ''))\n",
    "        return ''.join(chars)"
   ],
   "id": "72f9c844670ee2ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('spellchecker_artifacts.pkl', 'rb') as f:\n",
    "    artifacts = pickle.load(f)\n",
    "\n",
    "vocab = artifacts['vocab']\n",
    "config = artifacts['config']\n",
    "\n",
    "print(f\"Vocabulary size: {vocab.vocab_size}\")\n",
    "print(f\"Config: {config}\")\n",
    "if 'training_info' in artifacts:\n",
    "    print(f\"Training info: {artifacts['training_info']}\")"
   ],
   "id": "a5d0eb7ff0994296"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 5 - Load Model\n",
    "def load_model(model_path, config, vocab):\n",
    "    model = Seq2SeqSpeller(\n",
    "        vocab.vocab_size,\n",
    "        config['embed_dim'],\n",
    "        config['hidden_dim'],\n",
    "        config['dropout']\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model('spellchecker_model.pt', config, vocab)\n",
    "print(\"Model loaded successfully!\")"
   ],
   "id": "67f22df2e7a0472f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def beam_search_decode(model, word, vocab, beam_width=5, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = len(word) + 5\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        src = torch.tensor(vocab.encode(word)).unsqueeze(0).to(device)\n",
    "        src_len = torch.tensor([len(word)])\n",
    "\n",
    "        _, (hidden, cell) = model.encoder(src, src_len)\n",
    "\n",
    "        beams = [(0.0, [vocab.sos_idx], hidden, cell)]\n",
    "        completed = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            candidates = []\n",
    "\n",
    "            for score, seq, h, c in beams:\n",
    "                if seq[-1] == vocab.eos_idx:\n",
    "                    completed.append((score / len(seq), seq))\n",
    "                    continue\n",
    "\n",
    "                inp = torch.tensor([[seq[-1]]]).to(device)\n",
    "                output, new_h, new_c = model.decoder(inp, h, c)\n",
    "                log_probs = torch.log_softmax(output, dim=-1)\n",
    "\n",
    "                topk = log_probs.topk(beam_width)\n",
    "                for prob, idx in zip(topk.values[0], topk.indices[0]):\n",
    "                    candidates.append((\n",
    "                        score + prob.item(),\n",
    "                        seq + [idx.item()],\n",
    "                        new_h, new_c\n",
    "                    ))\n",
    "\n",
    "            if not candidates:\n",
    "                break\n",
    "\n",
    "            candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "            beams = candidates[:beam_width]\n",
    "\n",
    "        completed.extend([(s/len(seq), seq) for s, seq, _, _ in beams])\n",
    "\n",
    "        if completed:\n",
    "            best = max(completed, key=lambda x: x[0])\n",
    "            return vocab.decode(best[1])\n",
    "\n",
    "        return word"
   ],
   "id": "631a46948c021693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_cache = {'model': None, 'vocab': None}\n",
    "\n",
    "def correct_word(word: str, model_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a potentially misspelled Georgian word and returns the corrected version.\n",
    "    \"\"\"\n",
    "    global _cache\n",
    "\n",
    "    # Load model if not cached\n",
    "    if _cache['model'] is None:\n",
    "        with open('spellchecker_artifacts.pkl', 'rb') as f:\n",
    "            artifacts = pickle.load(f)\n",
    "\n",
    "        vocab = artifacts['vocab']\n",
    "        config = artifacts['config']\n",
    "\n",
    "        model = Seq2SeqSpeller(\n",
    "            vocab.vocab_size,\n",
    "            config['embed_dim'],\n",
    "            config['hidden_dim'],\n",
    "            config['dropout']\n",
    "        )\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        _cache['model'] = model\n",
    "        _cache['vocab'] = vocab\n",
    "\n",
    "    model = _cache['model']\n",
    "    vocab = _cache['vocab']\n",
    "\n",
    "    # Handle edge cases\n",
    "    if not word or len(word) < 1:\n",
    "        return word\n",
    "\n",
    "    # Filter non-Georgian characters\n",
    "    georgian_chars = set('აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ')\n",
    "    if not all(c in georgian_chars for c in word):\n",
    "        return word\n",
    "\n",
    "    # Beam search decode\n",
    "    result = beam_search_decode(model, word, vocab, beam_width=5)\n",
    "\n",
    "    return result if result else word"
   ],
   "id": "706b991c2893ecc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
